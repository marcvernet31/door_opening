{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "broad-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "collective-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "door1 = pd.read_csv(\"data/data_door1.txt\",  sep=\";\", header=None)\n",
    "door1 = door1.set_axis([\"Timestamp\", \"x\", \"y\", \"z\", \"pressure\"], axis=1, inplace=False)\n",
    "\n",
    "door2 = pd.read_csv(\"data/data_door2.txt\",  sep=\";\", header=None)\n",
    "# has 5 variables ???\n",
    "\n",
    "testdata = pd.read_csv(\"data/testdata.csv\", sep=\";\", header=None)\n",
    "testdata = testdata.set_axis([\"Timestamp\", \"x\", \"y\", \"z\", \"pressure\"], axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "peaceful-variance",
   "metadata": {},
   "outputs": [],
   "source": [
    "### calculate medians\n",
    "\n",
    "def calculateMedian(variable, size):\n",
    "    listOfMedians = list()\n",
    "    for i in range(0, len(variable)):\n",
    "        start = max(i - size//2, 0) # max to avoid negatives\n",
    "        end = min(i + (size-size//2), len(variable)) # evitar problemes amb parells\n",
    "\n",
    "        calculate_median = variable[start:end]\n",
    "        calculate_median.sort()\n",
    "        median = calculate_median[len(calculate_median)//2]\n",
    "        listOfMedians.append(median)\n",
    "    return listOfMedians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "given-resolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "door1[\"x\"] = calculateMedian(list(door1[\"x\"]), 100)\n",
    "door1[\"y\"] = calculateMedian(list(door1[\"x\"]), 100)\n",
    "door1[\"z\"] = calculateMedian(list(door1[\"x\"]), 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-lexington",
   "metadata": {},
   "source": [
    "### export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "affected-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# series | timestamp | value | label\n",
    "\n",
    "# Generate a Trainset compatible dataset\n",
    "def TRAINSETcompatible(dataframe, variable, serieName):\n",
    "\n",
    "    value = dataframe[variable]\n",
    "    originalTimestamps = dataframe[\"Timestamp\"]\n",
    "    series = [serieName] * len(value)\n",
    "\n",
    "    newTimestamp = list()\n",
    "    t_0 = datetime.now() \n",
    "    for i in range(len(value)):\n",
    "        t_i = str(t_0 + timedelta(seconds=int(originalTimestamps[i])))\n",
    "        t_i = t_i.replace(\" \", \"T\")\n",
    "        t_i = t_i[:-6]\n",
    "        t_i += \"000Z\" \n",
    "        newTimestamp.append(t_i)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['series'] = series\n",
    "    df[\"timestamp\"] = newTimestamp\n",
    "    df[\"value\"] = value\n",
    "    df[\"label\"] = \"\"\n",
    "\n",
    "    return df\n",
    "\n",
    "df_x = TRAINSETcompatible(door1[0:1000000], \"x\", \"serie_x\")\n",
    "df_y = TRAINSETcompatible(door1[0:1000000], \"y\", \"serie_y\")\n",
    "df_z = TRAINSETcompatible(door1[0:1000000], \"z\", \"serie_z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "confidential-photography",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x[0:250000].to_csv(\"to_label_datasets/x_0_250000.csv\", index=False)\n",
    "df_x[250000:500000].to_csv(\"to_label_datasets/x_250000_500000.csv\", index=False)\n",
    "df_x[500000:750000].to_csv(\"to_label_datasets/x_500000_750000.csv\", index=False)\n",
    "df_x[750000:1000000].to_csv(\"to_label_datasets/x_1000000_250000.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "statewide-substitute",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y[0:250000].to_csv(\"labeled_datasets/y_0_250000.csv\", index=False)\n",
    "df_y[250000:500000].to_csv(\"labeled_datasets/y_250000_500000.csv\", index=False)\n",
    "df_y[500000:750000].to_csv(\"labeled_datasets/y_500000_750000.csv\", index=False)\n",
    "df_y[750000:1000000].to_csv(\"labeled_datasets/y_750000_1000000.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-campbell",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y[0:250000].to_csv(\"labeled_datasets/y_0_250000.csv\", index=False)\n",
    "df_y[250000:500000].to_csv(\"labeled_datasets/y_250000_500000.csv\", index=False)\n",
    "df_y[500000:750000].to_csv(\"labeled_datasets/y_500000_750000.csv\", index=False)\n",
    "df_y[750000:1000000].to_csv(\"labeled_datasets/y_1000000_250000.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "vanilla-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "## nope\n",
    "df_doble = df_x[0:250000].append(df_y[0:250000])\n",
    "df_doble.to_csv(\"labeled_datasets/df_doble.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "individual-skirt",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>series_a</td>\n",
       "      <td>2021-12-05T10:41:51.000Z</td>\n",
       "      <td>0.517131</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>series_a</td>\n",
       "      <td>2021-12-05T10:42:31.000Z</td>\n",
       "      <td>0.421366</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>series_a</td>\n",
       "      <td>2021-12-05T10:43:11.000Z</td>\n",
       "      <td>0.344754</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>series_a</td>\n",
       "      <td>2021-12-05T10:43:51.000Z</td>\n",
       "      <td>0.344754</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>series_a</td>\n",
       "      <td>2021-12-05T10:44:30.000Z</td>\n",
       "      <td>0.325601</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     series                 timestamp     value label\n",
       "0  series_a  2021-12-05T10:41:51.000Z  0.517131      \n",
       "1  series_a  2021-12-05T10:42:31.000Z  0.421366      \n",
       "2  series_a  2021-12-05T10:43:11.000Z  0.344754      \n",
       "3  series_a  2021-12-05T10:43:51.000Z  0.344754      \n",
       "4  series_a  2021-12-05T10:44:30.000Z  0.325601      "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-academy",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "circular-symphony",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_x_labeled = pd.DataFrame()\n",
    "df_x_1 = pd.read_csv(\"labeled_datasets/x/x_0_250000-labeled.csv\")\n",
    "df_x_2 = pd.read_csv(\"labeled_datasets/x/x_250000_500000-labeled.csv\")\n",
    "df_x_3 = pd.read_csv(\"labeled_datasets/x/x_500000_750000-labeled.csv\")\n",
    "df_x_4 = pd.read_csv(\"labeled_datasets/x/x_750000_1000000-labeled.csv\")\n",
    "\n",
    "df_x_labeled = df_x_1.append(df_x_2).append(df_x_3).append(df_x_4)\n",
    "x_label = list(df_x_labeled[\"label\"])\n",
    "x_label = [1 if x == \"label_1\" else 0 for x in x_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "minimal-microphone",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-9e4c01d1ec7a>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  download[\"x_label\"] = x_label\n"
     ]
    }
   ],
   "source": [
    "download = door1[0:1000000]\n",
    "download[\"x_label\"] = x_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "instructional-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "download.to_csv(\"labeled_door1.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
